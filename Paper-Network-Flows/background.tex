\section{Background and Related Work}\label{sec:background}

Extensive research has focused on pre-installation Android malware detection through static and dynamic analysis. Dynamic approaches, like TaintDroid~\cite{DBLP:conf/osdi/EnckGCCJMS10}, DroidRanger~\cite{Zhou2012HeyYG}, and DroidScope~\cite{LKYanDroidscope}, monitor app behavior in real-time, offering high accuracy but significant performance overhead, limiting their practical use on mobile devices. In contrast, static methods such as Kirin~\cite{Enck2009}, Stowaway~\cite{DBLP:conf/ccs/FeltCHSW11}, and RiskRanker~\cite{GraceRiskranker2012} are efficient and scalable but heavily rely on manually defined patterns, hindering their effectiveness against novel malware. Additionally, these methods often lack transparency, making it difficult to understand their decision-making processes. The lack of understanding about Mining Android Sandbox (\mas) also appears in the \fhc, which presents an empirical study that explores the performance of \mas when using a large dataset of pair of apps for identifying malicious behavior.

%\subsection{Mining Android Sandbox}

%A sandbox is a controlled environment that isolates applications from the host system, preventing them from accessing or modifying files, networks, or other device data ~\cite{DBLP:journals/peerj-cs/MaassSCS16}. This isolation allows for safe testing and execution of potentially malicious code without compromising the device's integrity~\cite{DBLP:conf/esorics/BordoniCS17}. Such a need arises in various scenarios, including when dealing with untrusted user input, analyzing malware, or mitigating risks in compromised systems~\cite{DBLP:journals/peerj-cs/MaassSCS16}. A sandbox must protect the host machine and operating system from any harm caused by third-party software. To achieve this, it should provide the minimum necessary resources for program execution, ensuring that the program does not impact external resources.

%The \mas ~\cite{DBLP:conf/icse/JamrozikSZ16} employs test generation tools to examine an Android app's dynamic behavior and identify essential sensitive resources. By restricting access to these specific APIs, the sandbox safeguards app execution. The process involves two stages. In the exploratory phase, a benign app version is executed using test generation tools, recording the utilized sensitive APIs. Subsequently, during the execution phase, the sandbox limits the app's access to only the previously identified sensitive APIs, preventing malicious apps from accessing any unauthorized sensitive resources.

%Beyond its ability to generate Android sandboxes, the MAS approach is also effective in identifying malicious behavior in repackaged Android apps~\cite{DBLP:conf/wcre/BaoLL18}. The effectiveness of this approach is measured by its accuracy in correctly flagging malicious activities within repackaged versions of applications. In ~\cite{DBLP:jourals/jjc/Handrick22} the authors explore the use of static and dynamic analysis to improve the performance of the \mas. They propose a new approach based on taint analysis for malware identification demonstrating that when combining taint analysis with \mas, the percentage of malware identification is increased. Despite this results, both \mas and taint analysis present limitations that can be overcome using other approaches like, machine learning.

\subsection{Network Traffic Analysis}

System calls and network traffic are two key behaviors commonly analyzed in the dynamic analysis of Android apps. Recently, increased attention has been directed toward the network traffic generated by malware. As a result, researchers have begun analyzing and identifying malicious apps based on their network traffic. For example, signature-based detection methods assess malware by comparing it to known malware patterns. Griffin et al.~\cite{Griffin2009}  used 48-byte code sequences as signatures. Researchers have also explored automatically generating network signatures~\cite{PolygraphNewsome2005, Singh2004, Yegneswaran2005}, often focusing on worm identification. Perdisci et al. ~\cite{Perdisci2010} generated network signatures for mobile malware based on HTTP traffic, analyzing similarities and clustering malicious patterns. While effective against known threats, signature-based methods struggle to detect novel attacks due to their reliance on predefined patterns.

Some studies utilize text analysis for malware detection based on Packet/Flow textual features. Nan et al.~\cite{yuhong:usenix-2015} introduced UIPicker, a framework that uses NLP, machine learning, and program analysis to identify personal user information on a large scale. N-grams, a technique from NLP, have been applied to network protocol identification~\cite{YunWang2016}. Recon et al. ~\cite{ren:mobisys-2016} recently proposed a method to detect and prevent personal information leaks in mobile network traffic by analyzing key-value pairs. Some authors has also used Packet/Flow features statistically. Arora et al.~\cite{arora:ngmast-2014} compared malware traffic to benign network traffic, identifying deviations in network behavior using statistical features like average packet size, flow duration, and byte ratios. AppScanner~\cite{taylor:eurosp-2016} is a framework that uses statistical features of encrypted network traffic to automatically fingerprint and identify Android apps. Conti et al.~\cite{Conti2016} [19] analyzed encrypted Android traffic to identify user actions based on statistical features. However, statistical feature-based methods can have a high error rate due to their coarse-grained traffic characterization.

\subsection{Machine Learning (ML) Approach}

ML approach has been used in network traffic-based malware detection methods. Depending on the type of ML model used, these methods can be divided into two categories: (1) shallow learning techniques and (2) deep learning techniques. Shallow learning usually relies on handcrafted features based upon the target problem. These techniques include classic ML methods such as decision tree, random forest, KNN, and SVM. In contrast, deep learning methods are able to derive their own features directly from data by different hidden neural network layers.

Shallow techniques traditionally are used in malware detection methods as a classification problem. Researchers~\cite{RIBEIRO2020} have developed a host-based application to monitor device resource usage (e.g., CPU, memory, battery) and detect malware with over $90$\% accuracy using statistical and ML methods. Chen et al.~\cite{CHEN2018346} investigated the impact of data imbalance on Android malicious flow detection, finding that it can significantly reduce accuracy. They experimented with various classifiers on imbalanced datasets, demonstrating the effectiveness of ML for identifying malicious mobile traffic. Another study~\cite{lashkari:pst-2017} analyzed network traffic features to distinguish malicious traffic from normal traffic and identify malware types, using common classifiers like logistic regression, K-nearest neighbor (KNN), decision trees, and random forests. Feizollah et al.~\cite{feizollah2013study} also analyzed network traffic using nearly the same set of ML classifiers: KNN, decision trees, Na√Øve Bayes (NB), multi-layer perceptron (MLP), and support vector machine (SVM). The authors confirmed that KNN delivered the best performance among these classifiers. They also emphasized that new malware constantly emerges, making it necessary to continuously collect samples to train the models and keep them updated.

In summary, much of the related research in the literature focuses on selecting a set of widely used features from network traffic to achieve high accuracy in malware detection using ML algorithms. However, our work differs from these studies in several key aspects.

First, they analyzed a limited number of malware families (a maximum of 18), whereas we considered $116$ malware families. Second, we do not select our features based on the behavior of different malware families, which often requires expert knowledge or referencing previous work. Instead, we allow the machine to learn which features are most relevant for the models from the 3,194 features initially extracted in our experiments. Third, due to the challenge of manually generating input test cases, we used DroidBot~\cite{DBLP:conf/icse/LiYGC17}, an automated test case generation tool, to better simulate user interaction with the apps within a short time frame~\cite{DBLP:conf/kbse/ChoudharyGO15}. DroidBot outperforms similar tools in test case generation, as demonstrated in previous studies~\cite{DBLP:conf/kbse/ChoudharyGO15,DBLP:journals/jss/CostaMMSSBNR22}.


 %Research on deep learning-based malware detection using traffic analysis is limited. Alzaylaee et al.~\cite{ALZAYLAEE2020101663} developed a deep learning model to detect malicious Android apps using static and dynamic features. Wang~\cite{wang:iwqos-2018} proposed a URL-based malware detection method using a multi-view neural network. This network automatically creates multiple views of URLs and assigns attention weights to focus on different features. The method demonstrated high accuracy in detecting malware from different months of a specific year.


