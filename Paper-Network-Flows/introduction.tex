\section{Introduction}\label{sec:introduction}

Android is a powerful operating system based on Linux, commonly used in mobile technologies. It has more than $2.5$ million Android applications~\footnote{In this paper, we will use the terms Android Applications, Android Apps, and Apps interchangeably, to refer to Android software applications} (apps) available in the official Google Play Store until June 2023~\cite{Statista}. As its popularity rises, so does the risk of potential attacks, making Android-based devices prime targets for malicious apps (malware). In general, the main aim of malware is to gain unauthorized access to and exploit sensitive resources on a device~\cite{DBLP:conf/ccs/FeltFCHW11,DBLP:journals/eswa/SurendranTE20}. This can result in several issues, such as disruption of the device's normal functioning, battery drainage, information leakage, and more~\cite{DBLP:conf/ccs/FeltFCHW11,DBLP:conf/sp/ZhouJ12}.

A prevalent form of Android malware involves repackaging legitimate apps~\cite{DBLP:conf/wcre/BaoLL18, le2018towards}. These malicious variants can insert or modify the original apps with harmful code and release them on unofficial third-party markets~\cite{DBLP:journals/tdsc/TianYRTP20}. Researchers~\cite{DBLP:journals/tdsc/TianYRTP20,DBLP:conf/sp/ZhouJ12,DBLP:journals/compsec/MerloRSV21} show that the $86\%$ of malware are repackaged, highlighting the significant prevalence of these malicious apps currently. To counter this, several general-purpose Android malware detection techniques have been developed. For example, the Mining Android Sandbox (hereafter \mas) was created to analyze sensitive API calls by using sandboxes~\cite{DBLP:conf/icse/JamrozikSZ16}. 

Focused on app behavior abstraction, the \mas has proven effective in detecting repackaged malware, as demonstrated in previous work~\cite{DBLP:conf/wcre/BaoLL18}, which reported an accuracy of $75.5\%$ (77 out of 102 app pairs~\footnote{When we use the term App pair, we refer to the pairs (original and repackaged Android Application)}). However, the study by Bao et al.~\cite{DBLP:conf/wcre/BaoLL18} (hereafter \blls), evaluated the technique using only 102 app pairs, with a limited number of malware families, and do not explored the role of static and dynamic analysis on malicious behavior detection. Using the same app samples from \blls, Costa et al.~\cite{DBLP:jourals/jjc/Handrick22}, present an in-depth analysis related to the importance of static and dynamic analysis at malware detection, bringing evidence that both techniques complement each other, on Android malware classification task. 

Further exploration of the \mas was also identified at chapter 5, which recognized the necessity for additional studies beyond the \blls. The research presents an empirical evaluation of the \mas using a larger dataset (hereafter referred to as LargeDS), which is significantly bigger than the one used in the \blls. This dataset contains $4,076$ app pairs and $116$ malware families. The study reveals that when applied to the \cds, the accuracy of the \mas drops significantly, with an \fone of $0.54$, compared to the previously reported. This suggests that the effectiveness of the \mas in detecting and preventing malicious behaviors may not be generalizable to larger datasets.

Motivated by the limited results reported, we propose a new strategy to better counteract malicious apps, based on dynamic analysis of network traffic and machine learning (here after ML) algorithm. Now, we collect the traffic generated by both malicious and benign repackaged apps, utilizing an extension of \droidxp~\cite{DBLP:conf/scam/CostaMCMVBC20}. Beside collect data related to calls to sensitive APIs, the extension also gathers data related to the network traffic generated by the repackaged apps using the TcpDump tool. Feature engineering is then performed on the dataset to extract $86$ features from all apps using CICFlowMeter~\cite{DBLP:conf/icissp/LashkariDMG17} software.

Finally, we perform an automatic feature selection strategy based on Gini Importance, or Mean Decrease in Impurity (MDI)~\cite{james2023introduction}. These automatically selected features are used to train, and classify network flows into two categories: benign and malicious, using a supervised Random Forest algorithm. Our experimental results show that the proposed model outperforms previous state of arts approaches, achieving an \fone of 0.93. This improvement is especially notable in malware families that previously exhibited low false negative rates in earlier studies.\newline\newline


\textbf{Organization.} The rest of the paper is organized as follows: Section~\ref{sec:background} highlights the background and related work. Section~\ref{sec:Methodology} discuss the studies setting in details. The results of your approach are discussion in Section~\ref{sec:results}. After present implications and limitations at Section~\ref{sec:discussion}, we close with conclusion at Section~\ref{sec:conclusions}.


