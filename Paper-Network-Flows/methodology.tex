\section{Studies Setting}\label{sec:Methodology}

%\todo[inline]{O objetivo não é esse. O nosso objetivo é compreender
%  como uma abordagem, que explora dados de tráfego de rede, pode melhorar
%  a acurácia do \mas na detecção de malware.}

In this section, our goal is to build an in-depth understanding of the network traffic generated by apps at the network access point, and understand how an approach based on network flow analysis and ML can improve the accuracy of malware classification. To achieve this goal, we investigate the following research questions:

%\todo[inline]{As questões de pesquisa não estão bem formuladas. Primeiro,
%  questões do tipo 'yes' ou 'no' não nos apoia em um trabalho acadêmico,
%  melhor 'To what extent \ldots'. As outras questões estão genéricas.
%  Temos que estabelecer uma relação com mining sandbox}

\begin{enumerate}[(RQ1)]
\item \rqa
\item \rqb
\item \rqc
% \review{\item \rqe}
\end{enumerate}

To this end, we present how we collect data from network traffic, while executing a test case generation tools (Section~\ref{sec:data}). At Section~\ref{sec:feature} and Section~\ref{sec:set} we explain how we extract and preprocessing the features from our dataset. Finally, we describe the procedures we used to classify repackage apps as malware or non-malware, base on network traffic data and ML approach (Section~\ref{sec:learning}). The overview architecture of the proposed method is presented at Figure~\ref{fig:arq}.

\subsection{Malware Dataset}\label{sec:dataset}

%\todo[inline]{Precisamos discutir aqui como nós construímos o dataset? Isso não faz parte do artigo anterior?.
%  Podemos publicar esse dataset no Zenodo, ou no IEEE Data (https://ieee-dataport.org/submit-dataset). Podemos revisar
%um pouco aqui \ldots. Um cuidado, repack é um subset de AndroZoo.}

%\todo[inline]{Confuso. Temos 4,076 apps, sendo 1,777 originl and 4,076 repackaged. Frases como essa
%  exigem demais do leitor.}


To test and evaluate our proposal, we used the same dataset (\cds) described in Chapter 5. Here, we briefly describe the dataset used for our study.

As mentioned in the previous chapter, it contains 5,844 real-world apps from two repositories of repackaged Android apps (\repack~\cite{DBLP:journals/tse/LiBK21} and \amc~\cite{rafiq2022andromalpack}). Of these, 1,777 are original versions, and 4,067 are repackaged versions—multiple repackaged versions of the same original app may coexist within the LargeDS dataset. According to VirusTotal, at least two security engines identified 2,886 out of the 4,067 repackaged apps as malware ($70.96$\%), and 1,181 are benign.

The \cds contains several features about apps, including information about malware families, the similarity between the original and repackaged app versions, and the source of the Android app store. More details about the dataset features and how they were obtained can be found in Chapter 5 of this thesis.

\subsection{Data Collection}\label{sec:data}

The DroidXP~\cite{DBLP:conf/scam/CostaMCMVBC20} tool was initially designed to compare test case generation tools in terms of identifying malicious app behaviors using the \mas. This makes it a relevant tool for automating data collection for both static and dynamic analysis, following the steps outlined below:


%\todo[inline]{Não sei. acho que essa parte deveria estar em background. talvez de forma mais resumida.}

%\todo[inline]{Outra op\c c\~{a}o \'{e} termos uma se\c c\~{a}o sobre Data Collection, e iniciarmos essa
%  indicando que usamos duas estrat\'{e}gias de coleta de dados. Uma que coleta as informa\c c\~{o}es de
%  APIa sens\'{i}veis e outra que coleta o tr\'{a}fego de rede. Quebrar\'{i}amos as disucss\~{o}es
%espec\'{i}ficas em subsubse\c c\~{o}es. }

%\todo{inline}{Essa terminologia 'demonstrade' eh muito forte. Em vez de 'As demonstrade in the study (nao sei qual o estudo)', DroidXP can compare', poderia ser 'DroidXP was initially designe to compare \ldots'.}


%\todo{inlilne}{Vamos ser mais diretos. Em vez de 'the \fhc uses', coloca logo 'DroidXP instruments'. Acho que devemos remover alguns detalhes desse paper, e citar os outros trabalhos. Exemplo de talhes, 'As noted by the authors'. Outra coisa, estamos exigindo muito do leitor saber quem sao os autores, qual estudo estamos nos referindo, \ldots}

\begin{enumerate}[1.]
 \item \textbf{Instrumentation}:  All apps analyzed are instrumented to collect relevant information before execution. In the background, DroidXP leverages DroidFax~\cite{DBLP:conf/icsm/CaiR17a} to gather static information about the apps being analyzed.
 
   %\todo[inline]{Confuso essa parte inicial do texto ``As statistical result show that \ldots''. Na verdade, o par\'{a}grafo inteiro est\'{a} super confuso. Eu diria que toda essa se\c c\~{a}o MAS Data Collection deveria ser re-escrita. Quem \'{e} 'the author'?}
   
 \item \textbf{Execution}: DroidXP installs the instrumented versions of the apps on an Android emulator and restarts it before the actual execution. It then initiates a test case generation tool to execute all the apps and collect the dynamic data from the pre-programmed executions setup.
  
%\todo[inline]{A se\c c\~{a}o \'{e} sobre data collection. Vamos simplificar essa se\c c\~{a}o, deixa-la mais atrativa para um leitor.}   

\item \textbf{Data Collection}: At the end of the execution step, DroidXP again utilizes DroidFax, this time to compile all relevant information from the execution step, such as calls to sensitive APIs, and more. This step, and previous are crucial for dynamic analysis.
\end{enumerate}

For our study, we extended the original version of DroidXP by adding new functionality to its execution phase. This extension now uses the TcpDump tool to collect both inbound and outbound network traffic. With this adaptation, DroidXP can, in addition to capturing data for dynamic analysis, also generate packet capture (PCAP) files~\cite{DBLP:conf/iv/UhlarHR21} for all the apps analyzed.


As described in Section~\ref{sec:introduction}, previous studies have shown that $86\%$ of Android malware is found in repackaged original appss~\cite{DBLP:journals/tdsc/TianYRTP20,DBLP:conf/sp/ZhouJ12}. For this reason, we decided to extract the network traffic data generated exclusively by repackaged samples from the \cds dataset, which contains $4,067$ samples ($2,886$ malicious and $1,181$ benign), as detailed in Section~\ref{sec:dataset}. To capture the network traffic data, we followed the same criteria explained in the previous chapter, that is: each selected app was executed using DroidXP, via the DroidBot~\cite{DBLP:conf/icse/LiYGC17} test case generation tool, for a duration of $3$ minutes.

At the end of the exploration phase, we have multiple PCAP files, each corresponding to an analyzed app. A PCAP file contains copies of network packets, enabling dynamic analysis of both payloads and packet headers~\cite{DBLP:conf/iv/UhlarHR21}. Since storing and processing PCAP files is resource-intensive, it is necessary to perform a limited analysis of network segments rather than analyzing all of them. To extract the most relevant features for our study, we use CICflowMeter~\cite{DBLP:conf/icissp/LashkariDMG17} software, as described in the next section.


%Figure~\ref{fig:mine} show a overview of \mas data collection.


%\todo[inline]{Por que sandbox? Estamos sendo corretos aqui?}
%The study consider that a sandbox of app identifies a malware whenever the malicious app version makes a call to a sensitive API, which was not called during the exploratory phase of your original version, as present at Figure~\ref{fig:mine}.


\begin{figure*}[h]
  \centering
  
    \includegraphics[width=0.60\textwidth]{image/archic.png} \\[\abovecaptionskip]
    
  \caption{Overview architecture of the proposed malware detection method}\label{fig:arq}
\end{figure*}




%\todo[inline]{Aqui temos que dizer como eh a arquitetura dessa solu\c c\~{a}o. DroidXP foi usado 'as is', ou foi adaptado? Caso a gente esteja usando o DroidXP para coletar as duas coisas (apis sensiveis e trafego), devemos iniciar a se\c c\~{a}o indicando que adaptamos a vers\~{a}o do DroidXP de~\cite{}. A vers\~{a}o anterior coletava apenas as APIs sens\'{i}veis (descreve como era feito, de forma resumida). Com a adapta\c c\~{a}o, foi poss\'{i}vel coletar tamb\'{e}m informa\c c\~{o}es de tr\'{a}fego de redes. Nesse ponto voce comeca a discutir a parte de coleta de trafego de redes.}



%\todo[inline]{Por que n\~{a}o deixamos 'feature-extraction' como data collection?}
%\subsubsection{Feature Extraction}\label{sec:extraction}

%\todo[inline]{A pior coisa do mundo eh indicar que gera 86 feature e nao vai descreve-las por falta de espa\c co. Aqui pode ser escrito algo como '86 features, incluindo A, B, C.' Dessas 86 foram excluidas ABC features, por cause de \ldots. Outras XYZ foram excluidas pode \ldots. In the end, we considered only \ldots.}
\subsection{Feature Extraction}\label{sec:feature}

To extract features, we processed each traffic file (PCAP file) generated by DroidXP during the exploration step using the CICFlowMeter tool. This tool extracts feature sets in CSV format from the corresponding PCAP file. In the end, we combined all the CSV files into a single file containing a total of 86 features, including flow duration, destination port, number of transmitted bytes, and more. We did not consider all of these features, removing those that were irrelevant to our study, such as Flow ID, Source IP, Destination IP, Source Port, Source MAC, Destination MAC, Protocol, and Timestamp. In the end, we considered 78 features.

%\todo[inline]{Trabalho de doutorado. Precisamos justificar essas decis\~{o}es. Temos que explicar o que eh destination port, porque ela eh relevante, \ldots. Preferencialmente suportar essa decis\~{a}o por trabalhos anteriores.}

In a second step, we filtered our initial CSV file based on ``Destination Port''. Destination port numbers categorize the service being used in the traffic and is an important feature for analyzing network flow and potential malicious behavior~\cite{DBLP:journals/compsec/UmerSB17,DBLP:journals/comsur/SperottoSSMPS10}. Malware can often exploits ports such as 443 (HTTPS), 53 (DNS), or 80 (HTTP) to communicate with Command \& Control (C\&C) servers, carry out exploits, or blend in with normal traffic~\cite{DBLP:journals/comsur/SperottoSSMPS10}. Various datasets used to evaluate flow-based approaches include this important feature, like: CIDDS-001~\cite{Ring2017FlowbasedBD}, CICIDS17~\cite{DBLP:conf/icict/MahfouzVS19} and CTU-13~\cite{DBLP:journals/compsec/GarciaGSZ14}. Considering the importance of this feature, we explored the six most relevant destination ports, which appear most frequently in our initial CSV file, accounting for $74.25\%$ of all network traffic captured. (see Table~\ref{tab:port}).

\begin{table}[h]
  \caption{THE 6 MOST RELEVANT DESTINATION PORT.}
  \centering
  \begin{small}
    \begin{tabular}{rrlr}   \hline
 \# & Port & Description & Occurs  \\ \hline

1 &  443 &  Hypertext Transf. Protocol Secure &  1275293  \\ 
  2 &  53 & Domain Name System & 641965  \\ 
  3 &  80 & Hypertext Transfer Protocol &  38830  \\ 
  4 &  853 & DNS over TLS &  32784  \\ 
  5 &  5228 & Google Cloud Messaging &  26509  \\ 
  6 &  123 & Network Time Protocol & 9179  \\ 
  
   \hline

 \end{tabular}
 \end{small}
 \label{tab:port}
 \end{table}


\begin{table}[ht]
  \caption{STATISTICAL FUNCTIONS AT FEATURES.}
  \centering
  \begin{small}
    \begin{tabular}{rllrr}   \hline
 \# & Function & Description\\ \hline

1 &  min &  Minimum\\ 
  2 &  max & Maximum\\ 
  3 &  sum & Amount\\ 
  4 &  mean & Average\\ 
  5 &  std & Standard deviation \\ 
  6 &  median & Median\\ 
  7 &  count & Number of observation\\ 
  8 &  var & Variance\\ 
  9 &  skew & Skewness \\ 
   \hline

 \end{tabular}
 \end{small}
 \label{tab:function}
 \end{table}

%\todo[inline]{Talvez Data Preparation, Pre-processing, \ldots. Alguma coisa que os leitores estejam mais familiarizados.}
\subsection{Data Preprocessing}\label{sec:set}

%\todo[inline]{Justificar \ldots}

According to the literature~\cite{DBLP:conf/ichmi/Xie22,DBLP:journals/mta/AmiriebrahimabadiM24}, selecting relevant features is crucial for achieving good predictive power in a ML model. This can improve model accuracy and reduce training time. However, selecting the appropriate features is not a trivial task and often requires expert knowledge. For this reason, it is more effective to allow the machine to learn which features are most important~\cite{DBLP:journals/spe/FallahB22}. In this work, we extracted a subset of statistical features (Table~\ref{tab:function}) from the previous step and fed them into the model. Thereby, we group the initial 76 features (excluding Destination Port and Hash), with 6 Destination Ports, and 9 statistical features listed in Table~\ref{tab:function}. This combination greatly enhances the convenience of our experiment when we use it with ML algorithms to train detection models. By the end of this step, we have a initial dataset (here after \fds) with a total of 4,106 features ($76\times6\times9$) + Hash + Type (benign/malicious).


Still, high-dimensional datasets have a costly training time. To select the most relevant features and reduce their quantity, we took a second step by comparing the performance of four popular approaches using our initial \fds (4,104 features). We compared the performance of Linear Discriminant Analysis (LDA), Quadratic Discriminant Analysis (QDA), Logistic Regression, and the Random Forest algorithm~\cite{james2023introduction}. Subsequently, we also explored a novel classifier called the Energy-Based Flow Classifier (EFC), which is inspired by the inverse Potts model from quantum mechanics~\cite{DBLP:journals/tnsm/PontesSGBM21}.


To compare the performance of the algorithms, we train the
model based on the all 4,104 feature of \fds, and later use it for malware classification. In our learning-based classification procedure,
we split the feature set into a training set consisting of $70\%$
of the samples and a testing set consisting of $30\%$, randomly
selected from the \fds. The testing set is used solely
to evaluate the detection accuracy of the models. Among these methods, the supervised approach Random Forest delivered the best performance. This algorithm aggregates multiple decision trees, with each tree constructed using a random subset of features. This process decorrelates the trees, allowing for a more thorough exploration of the model and substantially improving predictive performance~\cite{james2023introduction}.

To achieve the best-fitting model, we also varied several model parameters using cross-validation~\cite{DBLP:phd/us/Stephenson22} on the training data. Cross-validation is a technique commonly used in ML to assess how well a model performs on an independent dataset~\cite{DBLP:journals/jsan/AwadF23}. This technique tests the model on different subsets of the data, helping to detect overfitting and making efficient use of the available data. For our experiment, cross-validation proposed the following values for five parameters in the Random Forest algorithm:

\begin{itemize}
    \item Number of trees in the forest: $190$
    \item The minimum number of samples required to split an internal node: $18$
    \item The minimum number of samples required to be at a leaf node: $3$
    \item The number of features to consider when looking for the best split: $\log_2(features)$
    \item The maximum depth of the tree: None~\footnote{If None, then nodes are expanded until all leaves}
\end{itemize}

Finally, using the Random Forest model with the parameters suggested by the cross-validation technique, we selected the 20 most relevant features based on Gini Importance, or Mean Decrease in Impurity (MDI)~\cite{james2023introduction}. In the end, our final \fds have the follow selected features listed in Table~\ref{tab:features}, extracted from the repackaged apps present at \cds, which we used in our research. 


%\todo[inline]{N\~{a}o poderia ser usado para justificar as decis\~{o}es da se\c c\~{a}o anterior? Aqui ja fala em Random Forest, mas eh algo que vai ser discutido mais na frente. }


\begin{table*}[ht]
  \caption{THE 20 MOST RELEVANT FEATURES.}
  \centering
  \begin{small}
    \begin{tabular}{rrlrrr}   \hline
 \# & Feature & Description & Function & Port &  Weights  \\ \hline

	1 &  \texttt{bwd\char`_byts\char`_b\char`_avg} &Average bytes per bulk in the backward direction & median & 443& 0.379153\\ 
	2 &  \texttt{bwd\char`_byts\char`_b\char`_avg} &  Average bytes per bulk in the backward direction &  max & 5228& 0.037761\\
	3 & \texttt{flow\char`_iat\char`_min} & Minimum time between two packets sent in the flow & max  & 443 &0.028584\\ 
	4 & \texttt{fwd\char`_iat\char`_mean} & Mean time between two packets sent in the forward direction & median & 443 &0.019078\\ 
	5 & \texttt{flow\char`_byts\char`_s} & Flow rate in bytes per second & median  & 443&0.018121\\
	6 & \texttt{bwd\char`_header\char`_len} & Total bytes used for headers in the backward direction &  mean  & 80& 0.015879\\ 
	7 &  \texttt{subflow\char`_bwd\char`_pkts} & The average number of packets in a sub flow in the bwd direr. &  mean  & 80&0.015492\\ 
	8 & \texttt{tot\char`_bwd\char`_pkts} & Total packets in the backward direction & mean  & 80 &0.013203\\ 
	9 & \texttt{flow\char`_iat\char`_std} & Standard deviation time between two packets sent in the flow &median & 443 &0.011182\\ 
	10 &  \texttt{bwd\char`_blk\char`_rate\char`_avg} & Average number of bulk rate in the backward direc. &  mean  & 443&0.009250\\ 
	11 & \texttt{bwd\char`_byts\char`_b\char`_avg} & Average number of bytes bulk rate in the backward direc. & max  & 443&0.009175\\
	12 & \texttt{fwd\char`_pkts\char`_s} & Number of forward packets per second & median  & 443&0.007700\\
	13 & \texttt{bwd\char`_pkt\char`_len\char`_std} & Standard deviation size of packet in backward direc. & median  & 443&0.006731\\ 
	14 & \texttt{bwd\char`_bytes\char`_b\char`_avg} & Average number of bytes bulk rate in the backward direc. & sum  & 80&0.006406\\ 
	15 & \texttt{bwd\char`_pkts\char`_len\char`_mean} & Mean size of packet in backward direction & max  & 443&0.006081\\ 
	16 & \texttt{bwd\char`_seg\char`_size\char`_avg} & Average size observed in the backward direction & max  & 443&0.005682\\ 
	17 & \texttt{fwd\char`_iat\char`_std} & Std. deviation time between two packets sent in the forward direc. & median  & 443 &0.005332\\ 
	18 & \texttt{flow\char`_pkts\char`_s} & Num. of bytes in the initial window in the fwd dir. &  median  & 443&0.004910\\ 
	19 & \texttt{bwd\char`_iat\char`_std} & Average size observed in the backward direction & median  & 443&0.004672\\ 
	20 & \texttt{bwd\char`_pkt\char`_len\char`_std} & Standard deviation size of packet in forward direction & skew  & 443&0.004476\\
   \hline

 \end{tabular}
 \end{small}
 \label{tab:features}
 \end{table*}


 %\todo[inline]{Essa se\c c\~{a}o poderia ser chamada de Data Analysis Procedures?}
\subsection{Data Analysis Procedures}\label{sec:learning}

%\todo[inline]{N\~{a}o sei se precisamos introduzir o conceito de ML aqui. }

%\todo[inline]{Aqui deveriamos descrever apenas os m\'{e}todos usados para an\'{a}lise de dados. A menos que se queira deixar claro que Random Forest foi melhor, e os outros n\~{a}o ser\~{a}o mais discutidos no texto. Se for esse o caminho, eh necess\'{a}rio apresentar a performance dos outros aqui. Handrick, eu sugiro fortemente voce ler alguns artigos que usam ML para detectar malwere, e tentar seguir uma estrutura semelhante. Definir ML, Cross-validation, \ldots, aqui n\~{a}o eh bom. Aqui devemos deixar claro nossos metodos de analise de dados. Mas no final, sugiro ler outros artigos e tornar essa secao mais proxima dos outros artigos.}

To explain our data analysis, we divide the procedure into two steps. In the first step, after achieving the best model and the best
features for analysis, we use ML technique to train all samples with the aim of providing predictions according to the trained model.

Finally, we triangulate the results of the \ml classification, with the outputs of \vt. This may lead to one of the following situations:

\begin{itemize}
\item {\bf True Positive (TP)}. The \ml label a repackaged version as a malware and, according to
  \vt, at least two \ses label the asset as a malware. This decision aligns with existing recommendations~\cite{vt-label,DBLP:journals/ese/KhanmohammadiEH19}
   
\item {\bf False Positive (FP)}. The \ml label a repackaged version as a malware and, according to \vt, at most one \se labels the asset as a malware.

\item {\bf False Negative (FN)}. The \ml does not label a repackaged version as a malware, and according to \vt, at least two \ses label the asset as a malware.
\end{itemize}

We compute \emph{Precision}, \emph{Recall}, and \emph{F-measure} ($F_1$) from
the number of TP, FP, and FN (using standard
formulae). We use basic statistics (average, median, standard deviation) to identify the
accuracy of the \ml for malware classification, at \cds.
